<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" type="image/x-icon" href="/static/favicon.ico">
  <title>Projection</title>
  <style>
    * { margin: 0; padding: 0; }
    body {
      background: #000;
      overflow: hidden;
      cursor: none;
    }
    canvas { display: block; }
    #status {
      position: fixed;
      top: 20px;
      left: 20px;
      color: #666;
      font-family: monospace;
      font-size: 14px;
      z-index: 100;
    }
  </style>
</head>
<body>
  <div id="status">Waiting for capture...</div>

  <script type="importmap">
  {
    "imports": {
      "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
      "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
    }
  }
  </script>
  <script type="module">
    import * as THREE from 'three';

    let scene, camera, renderer;
    let depthMesh;
    let params = {
      depthScale: 0.5,
      waveSpeed: 0,
      waveAmp: 0,
      hueShift: 0,
      meshRes: 128,
      gridOpacity: 0,
      gridSpacing: 20,
      gridWidth: 1,
      edgeOpacity: 0,
      edgeThreshold: 0.1,
      photoEdgeOpacity: 0,
      photoEdgeThreshold: 0.15
    };

    function init() {
      scene = new THREE.Scene();
      scene.background = new THREE.Color(0x000000);

      // Use perspective camera so we can see depth displacement
      camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 100);
      camera.position.set(0, 0, 2.5);

      renderer = new THREE.WebGLRenderer({ antialias: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.setPixelRatio(window.devicePixelRatio);
      document.body.appendChild(renderer.domElement);

      window.addEventListener('resize', onResize);
      animate();

      // Poll for updates from control panel
      pollForUpdates();
    }

    function onResize() {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    }

    let frameCount = 0;
    function animate() {
      requestAnimationFrame(animate);

      if (depthMesh) {
        const time = performance.now() * 0.001 * params.waveSpeed;
        depthMesh.material.uniforms.time.value = time;
        depthMesh.material.uniforms.waveAmp.value = params.waveAmp;
        depthMesh.material.uniforms.depthScale.value = params.depthScale;
        depthMesh.material.uniforms.hueShift.value = params.hueShift / 360;
        depthMesh.material.uniforms.gridOpacity.value = params.gridOpacity;
        depthMesh.material.uniforms.gridSpacing.value = params.gridSpacing;
        depthMesh.material.uniforms.gridWidth.value = params.gridWidth;
        depthMesh.material.uniforms.edgeOpacity.value = params.edgeOpacity;
        depthMesh.material.uniforms.edgeThreshold.value = params.edgeThreshold;
        depthMesh.material.uniforms.photoEdgeOpacity.value = params.photoEdgeOpacity;
        depthMesh.material.uniforms.photoEdgeThreshold.value = params.photoEdgeThreshold;
        depthMesh.material.needsUpdate = true;

        frameCount++;
        if (frameCount % 120 === 0) {
          console.log('Projection animate:', { time: time.toFixed(2), waveSpeed: params.waveSpeed, waveAmp: params.waveAmp });
        }
      }

      renderer.render(scene, camera);
    }

    function createDepthMesh(depthImg, originalImg, width, height) {
      if (depthMesh) {
        scene.remove(depthMesh);
        depthMesh.geometry.dispose();
        depthMesh.material.dispose();
      }

      const aspect = width / height;

      // Size plane to fill view
      const planeHeight = 2;
      const planeWidth = planeHeight * aspect;

      const geometry = new THREE.PlaneGeometry(planeWidth, planeHeight, params.meshRes, params.meshRes);

      const loader = new THREE.TextureLoader();
      const depthTexture = loader.load(depthImg);
      const originalTexture = loader.load(originalImg);

      const material = new THREE.ShaderMaterial({
        uniforms: {
          depthMap: { value: depthTexture },
          colorMap: { value: originalTexture },
          depthScale: { value: params.depthScale },
          time: { value: 0 },
          waveAmp: { value: params.waveAmp },
          hueShift: { value: params.hueShift / 360 },
          gridOpacity: { value: params.gridOpacity },
          gridSpacing: { value: params.gridSpacing },
          gridWidth: { value: params.gridWidth },
          edgeOpacity: { value: params.edgeOpacity },
          edgeThreshold: { value: params.edgeThreshold },
          photoEdgeOpacity: { value: params.photoEdgeOpacity },
          photoEdgeThreshold: { value: params.photoEdgeThreshold },
          resolution: { value: new THREE.Vector2(width, height) }
        },
        vertexShader: `
          uniform sampler2D depthMap;
          uniform float depthScale;
          uniform float time;
          uniform float waveAmp;
          varying vec2 vUv;
          varying float vDepth;

          void main() {
            vUv = uv;
            vec4 depth = texture2D(depthMap, uv);
            vDepth = depth.r;
            float displacement = depth.r * depthScale;
            displacement += sin(uv.x * 10.0 + time * 3.0) * sin(uv.y * 10.0 + time * 2.0) * waveAmp;
            vec3 newPosition = position + vec3(0.0, 0.0, displacement);
            gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
          }
        `,
        fragmentShader: `
          uniform sampler2D colorMap;
          uniform sampler2D depthMap;
          uniform float hueShift;
          uniform float time;
          uniform float waveAmp;
          uniform float gridOpacity;
          uniform float gridSpacing;
          uniform float gridWidth;
          uniform float edgeOpacity;
          uniform float edgeThreshold;
          uniform float photoEdgeOpacity;
          uniform float photoEdgeThreshold;
          uniform vec2 resolution;
          varying vec2 vUv;
          varying float vDepth;

          vec3 rgb2hsv(vec3 c) {
            vec4 K = vec4(0.0, -1.0/3.0, 2.0/3.0, -1.0);
            vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
            vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));
            float d = q.x - min(q.w, q.y);
            float e = 1.0e-10;
            return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
          }

          vec3 hsv2rgb(vec3 c) {
            vec4 K = vec4(1.0, 2.0/3.0, 1.0/3.0, 3.0);
            vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
            return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
          }

          // Calculate grid lines that follow depth surfaces
          float surfaceGrid(vec2 uv, float depth, float spacing, float lineWidth) {
            // Grid in screen space, offset by depth to align with surfaces
            float depthOffset = depth * 50.0;
            vec2 gridUv = uv * resolution / spacing;
            // Offset grid based on depth - creates perspective-aligned grids
            gridUv += vec2(depthOffset * 0.1, depthOffset * 0.1);

            vec2 grid = abs(fract(gridUv - 0.5) - 0.5);
            float lineX = smoothstep(lineWidth / spacing, 0.0, grid.x);
            float lineY = smoothstep(lineWidth / spacing, 0.0, grid.y);
            return max(lineX, lineY);
          }

          // Sobel edge detection on depth
          float detectDepthEdges(vec2 uv, float threshold) {
            vec2 texel = 1.0 / resolution;

            // Sample 3x3 neighborhood
            float tl = texture2D(depthMap, uv + vec2(-texel.x, texel.y)).r;
            float t  = texture2D(depthMap, uv + vec2(0.0, texel.y)).r;
            float tr = texture2D(depthMap, uv + vec2(texel.x, texel.y)).r;
            float l  = texture2D(depthMap, uv + vec2(-texel.x, 0.0)).r;
            float r  = texture2D(depthMap, uv + vec2(texel.x, 0.0)).r;
            float bl = texture2D(depthMap, uv + vec2(-texel.x, -texel.y)).r;
            float b  = texture2D(depthMap, uv + vec2(0.0, -texel.y)).r;
            float br = texture2D(depthMap, uv + vec2(texel.x, -texel.y)).r;

            // Sobel operators
            float gx = -tl - 2.0*l - bl + tr + 2.0*r + br;
            float gy = -tl - 2.0*t - tr + bl + 2.0*b + br;
            float edge = sqrt(gx*gx + gy*gy);

            return smoothstep(threshold * 0.5, threshold, edge);
          }

          // Sobel edge detection on color image (using luminance)
          float detectPhotoEdges(vec2 uv, float threshold) {
            vec2 texel = 1.0 / resolution;

            // Sample 3x3 neighborhood and convert to luminance
            float tl = dot(texture2D(colorMap, uv + vec2(-texel.x, texel.y)).rgb, vec3(0.299, 0.587, 0.114));
            float t  = dot(texture2D(colorMap, uv + vec2(0.0, texel.y)).rgb, vec3(0.299, 0.587, 0.114));
            float tr = dot(texture2D(colorMap, uv + vec2(texel.x, texel.y)).rgb, vec3(0.299, 0.587, 0.114));
            float l  = dot(texture2D(colorMap, uv + vec2(-texel.x, 0.0)).rgb, vec3(0.299, 0.587, 0.114));
            float r  = dot(texture2D(colorMap, uv + vec2(texel.x, 0.0)).rgb, vec3(0.299, 0.587, 0.114));
            float bl = dot(texture2D(colorMap, uv + vec2(-texel.x, -texel.y)).rgb, vec3(0.299, 0.587, 0.114));
            float b  = dot(texture2D(colorMap, uv + vec2(0.0, -texel.y)).rgb, vec3(0.299, 0.587, 0.114));
            float br = dot(texture2D(colorMap, uv + vec2(texel.x, -texel.y)).rgb, vec3(0.299, 0.587, 0.114));

            // Sobel operators
            float gx = -tl - 2.0*l - bl + tr + 2.0*r + br;
            float gy = -tl - 2.0*t - tr + bl + 2.0*b + br;
            float edge = sqrt(gx*gx + gy*gy);

            return smoothstep(threshold * 0.5, threshold, edge);
          }

          void main() {
            vec4 color = texture2D(colorMap, vUv);
            float colorWave = sin(vUv.x * 20.0 + time * 2.0) * sin(vUv.y * 20.0 + time * 1.5) * waveAmp * 0.5;
            vec3 hsv = rgb2hsv(color.rgb);
            hsv.x = fract(hsv.x + hueShift + colorWave);
            vec3 finalColor = hsv2rgb(hsv);

            // Grid lines - aligned to depth surfaces
            if (gridOpacity > 0.0) {
              float grid = surfaceGrid(vUv, vDepth, gridSpacing, gridWidth);
              vec3 gridColor = vec3(0.0, 1.0, 0.8); // Cyan grid
              finalColor = mix(finalColor, gridColor, grid * gridOpacity);
            }

            // Depth edge detection overlay
            if (edgeOpacity > 0.0) {
              float edge = detectDepthEdges(vUv, edgeThreshold);
              vec3 edgeColor = vec3(1.0, 0.2, 0.5); // Magenta edges
              finalColor = mix(finalColor, edgeColor, edge * edgeOpacity);
            }

            // Photo edge detection overlay
            if (photoEdgeOpacity > 0.0) {
              float edge = detectPhotoEdges(vUv, photoEdgeThreshold);
              vec3 edgeColor = vec3(1.0, 1.0, 0.0); // Yellow edges for photo
              finalColor = mix(finalColor, edgeColor, edge * photoEdgeOpacity);
            }

            gl_FragColor = vec4(finalColor, 1.0);
          }
        `,
        side: THREE.DoubleSide
      });

      depthMesh = new THREE.Mesh(geometry, material);
      scene.add(depthMesh);

      document.getElementById('status').style.display = 'none';
    }

    async function pollForUpdates() {
      try {
        const response = await fetch('/api/state');
        if (response.ok) {
          const state = await response.json();

          // Update params
          params.depthScale = state.depthScale;
          params.waveSpeed = state.waveSpeed;
          params.waveAmp = state.waveAmp;
          params.hueShift = state.hueShift;
          params.gridOpacity = state.gridOpacity ?? 0;
          params.gridSpacing = state.gridSpacing ?? 20;
          params.gridWidth = state.gridWidth ?? 1;
          params.edgeOpacity = state.edgeOpacity ?? 0;
          params.edgeThreshold = state.edgeThreshold ?? 0.1;
          params.photoEdgeOpacity = state.photoEdgeOpacity ?? 0;
          params.photoEdgeThreshold = state.photoEdgeThreshold ?? 0.15;

          // If we have new image data, update the mesh
          if (state.hasCapture && state.captureId !== window.lastCaptureId) {
            console.log('Loading capture:', state.captureId);
            window.lastCaptureId = state.captureId;
            document.getElementById('status').textContent = 'Loading capture...';
            const captureResponse = await fetch('/api/latest-capture');
            if (captureResponse.ok) {
              const data = await captureResponse.json();
              createDepthMesh(data.depth, data.original, data.width, data.height);
              console.log('Mesh created');
            }
          }
        }
      } catch (e) {
        console.log('Poll error:', e);
        document.getElementById('status').textContent = 'Connection error: ' + e.message;
        document.getElementById('status').style.display = 'block';
      }

      // Poll every 100ms
      setTimeout(pollForUpdates, 100);
    }

    // Initial load - try server capture first, fall back to default
    async function initialLoad() {
      try {
        const response = await fetch('/api/latest-capture');
        if (response.ok) {
          const data = await response.json();
          createDepthMesh(data.depth, data.original, data.width, data.height);
          console.log('Initial mesh loaded from server');
          return;
        }
      } catch (e) {
        console.log('No server capture, loading default');
      }

      // Load default image
      createDepthMesh('/static/default_depth.png', '/static/default_original.jpg', 504, 336);
      console.log('Default mesh loaded');
    }

    init();
    onResize();
    initialLoad();
  </script>
</body>
</html>
